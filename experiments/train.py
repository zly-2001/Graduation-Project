"""
ä¸“åˆ©å®Œæ•´è®­ç»ƒæµç¨‹
"""
import sys
import os
from pathlib import Path
current_file = os.path.abspath(__file__)           # train.py çš„ç»å¯¹è·¯å¾„
experiments_dir = os.path.dirname(current_file)    # experiments/
project_root = os.path.dirname(experiments_dir)    # watermark/

# æ·»åŠ åˆ°æœç´¢è·¯å¾„
sys.path.insert(0, project_root)

print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
# import sys
# sys.path.append('..')

import torch
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import math
import torchvision.utils as vutils
from PIL import Image

from models.encoder import Encoder
from models.decoder import Decoder
from models.attacks import HeterogeneousAttack
from models.sync_net import SyncNet
from utils.sync_pattern import SyncPatternGenerator
from utils.losses import CompositeLoss
from utils.dataset import get_dataloader
from utils.watermark_utils import WatermarkPreprocessor
def compute_psnr(a, b, max_val=2.0):
    # è¾“å…¥èŒƒå›´[-1,1]ï¼Œmax_val=2.0
    mse = torch.mean((a - b) ** 2)
    if mse == 0:
        return 99.0
    return 10 * math.log10((max_val ** 2) / mse.item())


def _gaussian_window(window_size=11, sigma=1.5, channels=3, device="cpu"):
    coords = torch.arange(window_size, device=device) - window_size // 2
    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
    g = (g / g.sum()).unsqueeze(0)
    window_1d = g
    window_2d = window_1d.T @ window_1d
    window = window_2d.expand(channels, 1, window_size, window_size)
    return window


def compute_ssim(img1, img2, window_size=11, sigma=1.5):
    # ç®€åŒ–ç‰ˆ SSIMï¼Œå‡è®¾è¾“å…¥èŒƒå›´[-1,1]
    device = img1.device
    channel = img1.size(1)
    window = _gaussian_window(window_size, sigma, channel, device=device)
    padding = window_size // 2
    mu1 = torch.nn.functional.conv2d(img1, window, padding=padding, groups=channel)
    mu2 = torch.nn.functional.conv2d(img2, window, padding=padding, groups=channel)
    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    sigma1_sq = torch.nn.functional.conv2d(img1 * img1, window, padding=padding, groups=channel) - mu1_sq
    sigma2_sq = torch.nn.functional.conv2d(img2 * img2, window, padding=padding, groups=channel) - mu2_sq
    sigma12 = torch.nn.functional.conv2d(img1 * img2, window, padding=padding, groups=channel) - mu1_mu2

    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
    return ssim_map.mean().item()

class WatermarkTrainer:
    def __init__(self, config):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        """
        self.config = config
        
        # è®¾å¤‡
        self.device = torch.device(
            "mps" if torch.backends.mps.is_available() else "cpu"
        )
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # æ¨¡å‹
        self.encoder = Encoder(config['watermark_length']).to(self.device)
        self.decoder = Decoder(config['watermark_length']).to(self.device)
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨æ¨¡æ‹ŸDDIMä»¥æå‡è®­ç»ƒé€Ÿåº¦ï¼ˆMac M4ä¼˜åŒ–ï¼‰
        # æ³¨æ„ï¼šæ¨¡æ‹ŸDDIMä½¿ç”¨ç›¸åŒçš„æ•°å­¦å…¬å¼ï¼Œä½†ä½¿ç”¨è½»é‡å·ç§¯ç½‘ç»œä»£æ›¿é¢„è®­ç»ƒUNet
        # å®Œå…¨ç¬¦åˆå®æ–½æ–¹å¼éœ€è¦å¯ç”¨çœŸæ­£çš„DDIMï¼ˆuse_ddim=Trueï¼‰ï¼Œä½†å¯ä»¥å…ˆéªŒè¯æµç¨‹
        self.attack = HeterogeneousAttack(
            use_ddim=False,       # âš ï¸ æš‚æ—¶ç¦ç”¨çœŸæ­£çš„DDIMï¼ˆä½¿ç”¨æ¨¡æ‹Ÿç‰ˆæœ¬ï¼Œè®­ç»ƒæ›´å¿«ï¼‰
            use_light_aigc=True,  # âœ… å¯ç”¨æ¨¡æ‹ŸDDIMï¼ˆä½¿ç”¨ç›¸åŒå…¬å¼ï¼Œè½»é‡å®ç°ï¼‰
            use_inpaint=False,    # âŒ Macä¸Šå¤ªæ…¢ï¼Œé»˜è®¤å…³é—­
            use_ip2p=False        # âŒ Macä¸Šå¤ªæ…¢ï¼Œé»˜è®¤å…³é—­
        ).to(self.device)
        
        # åŒæ­¥æ¨¡æ¿ç”Ÿæˆå™¨
        self.sync_generator = SyncPatternGenerator(config['image_size'])
        # åŒæ­¥ç½‘ç»œ
        self.sync_net = SyncNet().to(self.device)
        
        # æŸå¤±å‡½æ•°ï¼ˆLPIPSå¯èƒ½éœ€è¦CPUï¼‰
        self.criterion = CompositeLoss(
            lambda_p=config['lambda_p'],
            lambda_w=config['lambda_w']
        )

        # é¢„å¤„ç†å™¨ï¼ˆèº«ä»½+æ—¶é—´æˆ³+çº é”™+ç­¾å -> æ¯”ç‰¹è½½è·ï¼‰ï¼Œä½¿ç”¨æŒä¹…åŒ–å¯†é’¥
        key_dir = Path(config['save_dir']).parent / "keys"
        key_dir.mkdir(parents=True, exist_ok=True)
        private_key_path = key_dir / "private.pem"
        public_key_path = key_dir / "public.pem"
        self.preprocessor = WatermarkPreprocessor(
            private_key_path=str(private_key_path),
            public_key_path=str(public_key_path),
            target_bit_len=config['watermark_length'],
        )
        # é¦–æ¬¡ç”Ÿæˆæ—¶ä¿å­˜å¯†é’¥ï¼Œä¾¿äºæå–ç«¯éªŒç­¾
        if not private_key_path.exists() or not public_key_path.exists():
            self.preprocessor.save_keys(private_key_path, public_key_path)
        
        # ä¼˜åŒ–å™¨ï¼ˆAdamWï¼‰
        self.optimizer = optim.AdamW(
            list(self.encoder.parameters()) + 
            list(self.decoder.parameters()),
            lr=config['lr']
        )
        # åŒæ­¥ç½‘ç»œä¼˜åŒ–å™¨
        self.sync_optimizer = optim.Adam(
            self.sync_net.parameters(),
            lr=config.get('sync_lr', config['lr'])
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = optim.lr_scheduler.StepLR(
            self.optimizer,
            step_size=config['lr_step'],
            gamma=0.5
        )
        self.sync_scheduler = optim.lr_scheduler.StepLR(
            self.sync_optimizer,
            step_size=config['lr_step'],
            gamma=0.5
        )
        
        # TensorBoard
        self.writer = SummaryWriter(config['log_dir'])
        
        # æ•°æ®åŠ è½½å™¨
        self.train_loader = get_dataloader(
            config['train_dir'],
            batch_size=config['batch_size'],
            num_workers=config['num_workers'],
            preprocessor=self.preprocessor,
            pin_memory=config.get('pin_memory', True),
            watermark_length=config['watermark_length']
        )
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼Œç”¨äºéªŒè¯ï¼Œä¸ä¼šå‚ä¸è®­ç»ƒï¼‰
        test_dir = os.path.join(Path(config['train_dir']).parent, 'test_images')
        self.test_loader = None
        if os.path.exists(test_dir) and len(os.listdir(test_dir)) > 0:
            print(f"ğŸ“Š æ£€æµ‹åˆ°æµ‹è¯•é›†: {test_dir} (ç”¨äºéªŒè¯ï¼Œä¸ä¼šå‚ä¸è®­ç»ƒ)")
            self.test_loader = get_dataloader(
                test_dir,
                batch_size=min(4, config['batch_size']),  # æµ‹è¯•æ—¶batchå¯ä»¥å°ä¸€ç‚¹
                num_workers=0,  # æµ‹è¯•æ—¶ä¸éœ€è¦å¤šè¿›ç¨‹
                preprocessor=self.preprocessor,
                watermark_length=config['watermark_length']
            )
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•é›† ({test_dir})ï¼Œå°†åªåœ¨è®­ç»ƒé›†ä¸ŠéªŒè¯")
        
        # å¯è§†åŒ–ä¿å­˜ç›®å½•
        self.vis_dir = os.path.join(Path(config['save_dir']).parent, 'visualizations')
        os.makedirs(self.vis_dir, exist_ok=True)
    
    def train_epoch(self, epoch):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        """
        self.encoder.train()
        self.decoder.train()
        self.sync_net.train()
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}')
        epoch_losses = {'total': 0, 'perceptual': 0, 'watermark': 0}
        epoch_metrics = {'ber': 0, 'psnr': 0, 'ssim': 0}
        
        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            images = batch['image'].to(self.device)
            watermarks = batch['watermark'].to(self.device)
            
            # ç”ŸæˆåŒæ­¥æ¨¡æ¿
            sync_patterns = torch.stack([
                self.sync_generator.generate()
                for _ in range(images.size(0))
            ]).unsqueeze(1).to(self.device)

            # ===== åŒæ­¥ç½‘ç»œè®­ç»ƒï¼ˆéšæœºä»¿å°„ -> å›å½’é€†å˜æ¢ï¼‰=====
            # éšæœºä»¿å°„å‚æ•°
            angle = (torch.rand(images.size(0)) * 30 - 15).to(self.device)  # [-15,15]åº¦
            scale = (torch.rand(images.size(0)) * 0.4 + 0.8).to(self.device)  # [0.8,1.2]
            tx = (torch.rand(images.size(0)) * 0.1 - 0.05).to(self.device)    # [-0.05,0.05] å½’ä¸€åŒ–å¹³ç§»
            ty = (torch.rand(images.size(0)) * 0.1 - 0.05).to(self.device)
            rad = angle * torch.pi / 180
            cos_a = torch.cos(rad) * scale
            sin_a = torch.sin(rad) * scale
            theta_true = torch.zeros(images.size(0), 2, 3, device=self.device)
            theta_true[:,0,0] = cos_a; theta_true[:,0,1] = -sin_a; theta_true[:,0,2] = tx
            theta_true[:,1,0] = sin_a; theta_true[:,1,1] =  cos_a; theta_true[:,1,2] = ty

            grid = torch.nn.functional.affine_grid(theta_true, sync_patterns.size(), align_corners=False)
            warped = torch.nn.functional.grid_sample(sync_patterns, grid, align_corners=False)

            pred_theta = self.sync_net(warped)
            # æƒåˆ©è¦æ±‚7ï¼šL_sync = ||M - M_gt||F (FrobeniusèŒƒæ•°)
            sync_loss = torch.norm(pred_theta - theta_true, p='fro')
            self.sync_optimizer.zero_grad()
            sync_loss.backward()
            self.sync_optimizer.step()
            
            # å‰å‘ä¼ æ’­
            # S2: åµŒå…¥æ°´å°
            watermarked = self.encoder(images, watermarks, sync_patterns)
            
            # S3: æ¨¡æ‹Ÿæ”»å‡»
            attacked = self.attack(watermarked)
            
            # S4: æå–æ°´å°
            pred_watermarks = self.decoder(attacked)
            
            # è®¡ç®—æŸå¤±
            # æ³¨æ„ï¼šLPIPSéœ€è¦CPU
            losses = self.criterion(
                watermarked.cpu(),
                images.cpu(),
                pred_watermarks,
                watermarks
            )
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            losses['total'].backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(
                list(self.encoder.parameters()) + 
                list(self.decoder.parameters()),
                max_norm=1.0
            )
            
            self.optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            for k in epoch_losses:
                epoch_losses[k] += losses[k].item()
            # æŒ‡æ ‡ï¼šBER/PSNR/SSIM
            with torch.no_grad():
                pred_bits = (pred_watermarks > 0.5).float()
                ber = (pred_bits != watermarks).float().mean().item()
                psnr = compute_psnr(watermarked.detach(), images.detach())
                ssim = compute_ssim(watermarked.detach(), images.detach())
                epoch_metrics['ber'] += ber
                epoch_metrics['psnr'] += psnr
                epoch_metrics['ssim'] += ssim
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f"{losses['total'].item():.4f}",
                'p_loss': f"{losses['perceptual'].item():.4f}",
                'w_loss': f"{losses['watermark'].item():.4f}",
                'ber': f"{ber:.3f}"
            })
            
            # TensorBoardè®°å½•
            global_step = epoch * len(self.train_loader) + batch_idx
            for k, v in losses.items():
                self.writer.add_scalar(f'train/{k}', v.item(), global_step)
            self.writer.add_scalar('train/ber', ber, global_step)
            self.writer.add_scalar('train/psnr', psnr, global_step)
            self.writer.add_scalar('train/ssim', ssim, global_step)
            
            # æ¯ä¸ªepochçš„ç¬¬ä¸€ä¸ªbatchä¿å­˜å¯è§†åŒ–ï¼ˆé¿å…ä¿å­˜å¤ªå¤šï¼‰
            if batch_idx == 0:
                self._save_visualization(
                    images, watermarked, attacked, pred_watermarks, watermarks,
                    epoch, global_step
                )
        
        # å¹³å‡æŸå¤±
        for k in epoch_losses:
            epoch_losses[k] /= len(self.train_loader)
        for k in epoch_metrics:
            epoch_metrics[k] /= len(self.train_loader)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.sync_scheduler.step()
        
        # åˆå¹¶æŒ‡æ ‡
        all_metrics = {**epoch_losses, **epoch_metrics}
        
        # åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.test_loader is not None:
            test_metrics = self._validate_on_test_set(epoch)
            all_metrics.update({f'test_{k}': v for k, v in test_metrics.items()})
        
        return all_metrics
    
    def train(self, resume_from=None, train_batch_epochs=None):
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        
        Args:
            resume_from: ä»å“ªä¸ªcheckpointæ¢å¤ï¼ˆNone=è‡ªåŠ¨æ£€æµ‹, 'best'=æœ€ä½³æ¨¡å‹, 'latest'=æœ€æ–°epoch, æˆ–å…·ä½“è·¯å¾„ï¼‰
            train_batch_epochs: æ¯æ¬¡è®­ç»ƒçš„è½®æ•°ï¼ˆNone=è®­ç»ƒåˆ°config['epochs']ï¼Œå¦åˆ™åªè®­ç»ƒæŒ‡å®šè½®æ•°åä¿å­˜å¹¶é€€å‡ºï¼‰
        """
        print(f"\n{'='*50}")
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒæ°´å°ç³»ç»Ÿ")
        print(f"{'='*50}\n")
        
        # æ¢å¤è®­ç»ƒ
        start_epoch = 1
        best_loss = float('inf')
        
        # è‡ªåŠ¨æ£€æµ‹checkpointï¼ˆå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šresume_fromï¼‰
        if resume_from is None:
            # è‡ªåŠ¨æ£€æµ‹ï¼šä¼˜å…ˆä½¿ç”¨latestï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨best
            if os.path.exists(self.config['save_dir']):
                checkpoints = [f for f in os.listdir(self.config['save_dir']) if f.startswith('epoch_') and f.endswith('.pth')]
                if checkpoints:
                    # æ‰¾åˆ°æœ€æ–°çš„epoch checkpoint
                    latest = max(checkpoints, key=lambda x: int(x.split('_')[1].split('.')[0]))
                    checkpoint_path = os.path.join(self.config['save_dir'], latest)
                    resume_from = checkpoint_path
                    print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°checkpoint: {latest}")
                elif os.path.exists(os.path.join(self.config['save_dir'], 'best.pth')):
                    checkpoint_path = os.path.join(self.config['save_dir'], 'best.pth')
                    resume_from = checkpoint_path
                    print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°checkpoint: best.pth")
        
        if resume_from:
            if resume_from == 'best':
                checkpoint_path = os.path.join(self.config['save_dir'], 'best.pth')
            elif resume_from == 'latest':
                # æ‰¾åˆ°æœ€æ–°çš„epoch checkpoint
                if os.path.exists(self.config['save_dir']):
                    checkpoints = [f for f in os.listdir(self.config['save_dir']) if f.startswith('epoch_') and f.endswith('.pth')]
                    if checkpoints:
                        latest = max(checkpoints, key=lambda x: int(x.split('_')[1].split('.')[0]))
                        checkpoint_path = os.path.join(self.config['save_dir'], latest)
                    else:
                        checkpoint_path = os.path.join(self.config['save_dir'], 'best.pth')
                else:
                    checkpoint_path = None
            else:
                checkpoint_path = resume_from
            
            if checkpoint_path and os.path.exists(checkpoint_path):
                start_epoch, best_loss = self.load_checkpoint(checkpoint_path, resume_training=True)
        
        # ç¡®å®šè®­ç»ƒç»“æŸçš„epoch
        if train_batch_epochs is not None:
            # åˆ†æ‰¹æ¬¡è®­ç»ƒï¼šåªè®­ç»ƒæŒ‡å®šè½®æ•°
            end_epoch = start_epoch + train_batch_epochs - 1
            max_epoch = self.config['epochs']
            if end_epoch > max_epoch:
                end_epoch = max_epoch
            print(f"ğŸ“Œ åˆ†æ‰¹æ¬¡è®­ç»ƒæ¨¡å¼ï¼šä»epoch {start_epoch} è®­ç»ƒåˆ° epoch {end_epoch} (å…±{train_batch_epochs}è½®)")
        else:
            # æ­£å¸¸è®­ç»ƒï¼šè®­ç»ƒåˆ°é…ç½®çš„epochs
            end_epoch = self.config['epochs']
            print(f"ğŸ“Œ å®Œæ•´è®­ç»ƒæ¨¡å¼ï¼šä»epoch {start_epoch} è®­ç»ƒåˆ° epoch {end_epoch}")
        
        for epoch in range(start_epoch, end_epoch + 1):
            # è®­ç»ƒ
            losses = self.train_epoch(epoch)
            
            # å­¦ä¹ ç‡è°ƒæ•´
            self.scheduler.step()
            
            # æ‰“å°
            print(f"\n{'='*60}")
            print(f"Epoch {epoch}/{self.config['epochs']}:")
            print(f"  ğŸ“Š è®­ç»ƒé›†æŒ‡æ ‡:")
            print(f"    Total Loss: {losses['total']:.4f}")
            print(f"    Perceptual: {losses['perceptual']:.4f}")
            print(f"    Watermark:  {losses['watermark']:.4f}")
            print(f"    BER:        {losses['ber']:.4f}")
            print(f"    PSNR:       {losses['psnr']:.2f} dB")
            print(f"    SSIM:       {losses['ssim']:.4f}")
            print(f"    LR:         {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œæ‰“å°æµ‹è¯•æŒ‡æ ‡
            if self.test_loader is not None and f'test_ber' in losses:
                print(f"  ğŸ§ª æµ‹è¯•é›†æŒ‡æ ‡:")
                print(f"    BER:        {losses.get('test_ber', 0):.4f}")
                print(f"    PSNR:       {losses.get('test_psnr', 0):.2f} dB")
                print(f"    SSIM:       {losses.get('test_ssim', 0):.4f}")
            
            print(f"  ğŸ’¾ å¯è§†åŒ–å·²ä¿å­˜: {self.vis_dir}/epoch_{epoch:03d}_*.png")
            print(f"{'='*60}")
            
            # ä¿å­˜æ¨¡å‹
            if losses['total'] < best_loss:
                best_loss = losses['total']
                self.save_checkpoint(epoch, 'best', best_loss=best_loss)
                print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (loss={best_loss:.4f})")
            
            # å®šæœŸä¿å­˜
            if epoch % self.config['save_interval'] == 0:
                self.save_checkpoint(epoch, f'epoch_{epoch}')
        
        # åˆ†æ‰¹æ¬¡è®­ç»ƒï¼šè®­ç»ƒå®ŒæŒ‡å®šè½®æ•°åä¿å­˜å¹¶é€€å‡º
        if train_batch_epochs is not None:
            # ä¿å­˜å½“å‰è¿›åº¦
            self.save_checkpoint(epoch, f'epoch_{epoch}')
            print(f"\nâœ… æœ¬æ¬¡è®­ç»ƒå®Œæˆï¼å·²è®­ç»ƒ {train_batch_epochs} è½® (epoch {start_epoch} â†’ {epoch})")
            print(f"ğŸ’¾ å·²ä¿å­˜checkpoint: epoch_{epoch}.pth")
            if epoch < self.config['epochs']:
                remaining = self.config['epochs'] - epoch
                print(f"ğŸ“Œ å‰©ä½™ {remaining} è½®ï¼Œä¸‹æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ç»§ç»­è®­ç»ƒ")
                print(f"   ä¸‹æ¬¡è¿è¡Œ: python experiments/train.py (ä¼šè‡ªåŠ¨ä»epoch {epoch+1}ç»§ç»­)")
            else:
                print(f"ğŸ‰ æ‰€æœ‰è®­ç»ƒå·²å®Œæˆï¼(å…±{self.config['epochs']}è½®)")
        else:
            print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        
        self.writer.close()
    
    def save_checkpoint(self, epoch, name, best_loss=None):
        """
        ä¿å­˜æ¨¡å‹
        """
        os.makedirs(self.config['save_dir'], exist_ok=True)
        
        checkpoint = {
            'epoch': epoch,
            'encoder': self.encoder.state_dict(),
            'decoder': self.decoder.state_dict(),
            'sync_net': self.sync_net.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'sync_optimizer': self.sync_optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict(),
            'sync_scheduler': self.sync_scheduler.state_dict(),
            'config': self.config
        }
        if best_loss is not None:
            checkpoint['best_loss'] = best_loss
        
        path = os.path.join(self.config['save_dir'], f'{name}.pth')
        torch.save(checkpoint, path)
    
    def load_checkpoint(self, checkpoint_path, resume_training=True):
        """
        åŠ è½½æ£€æŸ¥ç‚¹ï¼Œæ”¯æŒæ¢å¤è®­ç»ƒ
        
        Args:
            checkpoint_path: checkpointæ–‡ä»¶è·¯å¾„
            resume_training: æ˜¯å¦æ¢å¤è®­ç»ƒï¼ˆTrue=ç»§ç»­è®­ç»ƒï¼ŒFalse=åªåŠ è½½æ¨¡å‹ï¼‰
        
        Returns:
            start_epoch: å¼€å§‹çš„epochï¼ˆå¦‚æœæ¢å¤è®­ç»ƒï¼‰
            best_loss: æœ€ä½³lossï¼ˆå¦‚æœcheckpointä¸­æœ‰ï¼‰
        """
        if not os.path.exists(checkpoint_path):
            print(f"âš ï¸ Checkpointä¸å­˜åœ¨: {checkpoint_path}")
            return 0, float('inf')
        
        print(f"ğŸ“‚ åŠ è½½checkpoint: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        # åŠ è½½æ¨¡å‹æƒé‡
        self.encoder.load_state_dict(checkpoint['encoder'])
        self.decoder.load_state_dict(checkpoint['decoder'])
        if 'sync_net' in checkpoint:
            self.sync_net.load_state_dict(checkpoint['sync_net'])
        
        best_loss = checkpoint.get('best_loss', float('inf'))
        
        if resume_training:
            # æ¢å¤è®­ç»ƒçŠ¶æ€
            if 'optimizer' in checkpoint:
                self.optimizer.load_state_dict(checkpoint['optimizer'])
            if 'sync_optimizer' in checkpoint:
                self.sync_optimizer.load_state_dict(checkpoint['sync_optimizer'])
            if 'scheduler' in checkpoint:
                self.scheduler.load_state_dict(checkpoint['scheduler'])
            if 'sync_scheduler' in checkpoint:
                self.sync_scheduler.load_state_dict(checkpoint['sync_scheduler'])
            
            start_epoch = checkpoint.get('epoch', 0) + 1
            print(f"âœ… ä»epoch {start_epoch}æ¢å¤è®­ç»ƒ (best_loss={best_loss:.4f})")
            return start_epoch, best_loss
        else:
            print(f"âœ… åŠ è½½æ¨¡å‹æƒé‡ï¼ˆepoch {checkpoint.get('epoch', 0)}ï¼‰")
            return 0, best_loss
    
    def _save_visualization(self, images, watermarked, attacked, pred_watermarks, true_watermarks, epoch, step):
        """
        ä¿å­˜è®­ç»ƒæ•ˆæœå¯è§†åŒ–
        
        ä¿å­˜ï¼š
        1. åŸå§‹å›¾åƒ vs å¸¦æ°´å°å›¾åƒï¼ˆå¯¹æ¯”ä¸å¯è§æ€§ï¼‰
        2. å¸¦æ°´å°å›¾åƒ vs æ”»å‡»åå›¾åƒï¼ˆå±•ç¤ºæ”»å‡»æ•ˆæœï¼‰
        3. æ°´å°æå–å¯¹æ¯”ï¼ˆçœŸå® vs é¢„æµ‹ï¼‰
        """
        with torch.no_grad():
            # åªä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬
            img_orig = images[0:1].cpu()
            img_wm = watermarked[0:1].cpu()
            img_att = attacked[0:1].cpu()
            
            # è½¬æ¢ä¸º[0,1]èŒƒå›´ç”¨äºä¿å­˜
            img_orig_vis = (img_orig + 1.0) / 2.0
            img_wm_vis = (img_wm + 1.0) / 2.0
            img_att_vis = (img_att + 1.0) / 2.0
            
            # ä¿å­˜å¯¹æ¯”å›¾ï¼šåŸå§‹ vs å¸¦æ°´å°
            comparison1 = torch.cat([img_orig_vis, img_wm_vis], dim=3)  # æ°´å¹³æ‹¼æ¥
            vutils.save_image(
                comparison1,
                os.path.join(self.vis_dir, f'epoch_{epoch:03d}_original_vs_watermarked.png'),
                nrow=1,
                normalize=False
            )
            
            # ä¿å­˜å¯¹æ¯”å›¾ï¼šå¸¦æ°´å° vs æ”»å‡»å
            comparison2 = torch.cat([img_wm_vis, img_att_vis], dim=3)
            vutils.save_image(
                comparison2,
                os.path.join(self.vis_dir, f'epoch_{epoch:03d}_watermarked_vs_attacked.png'),
                nrow=1,
                normalize=False
            )
            
            # ä¿å­˜å®Œæ•´æµç¨‹ï¼šåŸå§‹ -> å¸¦æ°´å° -> æ”»å‡»å
            comparison3 = torch.cat([img_orig_vis, img_wm_vis, img_att_vis], dim=3)
            vutils.save_image(
                comparison3,
                os.path.join(self.vis_dir, f'epoch_{epoch:03d}_full_pipeline.png'),
                nrow=1,
                normalize=False
            )
            
            # è®°å½•åˆ°TensorBoard
            self.writer.add_image('visualization/original_vs_watermarked', comparison1[0], step)
            self.writer.add_image('visualization/watermarked_vs_attacked', comparison2[0], step)
            self.writer.add_image('visualization/full_pipeline', comparison3[0], step)
            
            # è®¡ç®—å¹¶ä¿å­˜æ°´å°æå–å‡†ç¡®ç‡ï¼ˆå‰64ä½ï¼ŒåŸå§‹ä¿¡æ¯éƒ¨åˆ†ï¼‰
            pred_bits = (pred_watermarks[0] > 0.5).float().cpu().numpy()
            true_bits = true_watermarks[0].cpu().numpy()
            accuracy = 1.0 - (pred_bits != true_bits).mean()
            
            # ä¿å­˜æ°´å°å¯¹æ¯”æ–‡æœ¬
            with open(os.path.join(self.vis_dir, f'epoch_{epoch:03d}_watermark_info.txt'), 'w') as f:
                f.write(f"Epoch {epoch}, Step {step}\n")
                f.write(f"æ°´å°æå–å‡†ç¡®ç‡: {accuracy*100:.2f}%\n")
                f.write(f"å‰32ä½çœŸå®: {''.join([str(int(b)) for b in true_bits[:32]])}\n")
                f.write(f"å‰32ä½é¢„æµ‹: {''.join([str(int(b)) for b in pred_bits[:32]])}\n")
    
    def _validate_on_test_set(self, epoch):
        """
        åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯ï¼ˆä¸ä¼šå½±å“è®­ç»ƒï¼Œåªæ˜¯è¯„ä¼°ï¼‰
        
        æ³¨æ„ï¼šæµ‹è¯•æ•°æ®ä¸ä¼šè¢«æ±¡æŸ“ï¼Œå› ä¸ºï¼š
        1. æµ‹è¯•é›†åªç”¨äºå‰å‘ä¼ æ’­ï¼ˆtorch.no_grad()ï¼‰
        2. ä¸ä¼šè¿›è¡Œåå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
        3. æµ‹è¯•é›†å’Œè®­ç»ƒé›†å®Œå…¨åˆ†ç¦»
        """
        self.encoder.eval()
        self.decoder.eval()
        self.attack.eval()
        
        test_metrics = {
            'ber': 0.0,
            'psnr': 0.0,
            'ssim': 0.0
        }
        
        with torch.no_grad():
            for batch in self.test_loader:
                images = batch['image'].to(self.device)
                watermarks = batch['watermark'].to(self.device)
                
                # ç”ŸæˆåŒæ­¥æ¨¡æ¿
                sync_patterns = []
                for _ in range(images.size(0)):
                    pattern = self.sync_generator.generate()
                    sync_patterns.append(pattern)
                sync_patterns = torch.stack(sync_patterns, dim=0).unsqueeze(1).to(self.device)
                
                # å‰å‘ä¼ æ’­ï¼ˆä¸è®­ç»ƒï¼‰
                watermarked = self.encoder(images, watermarks, sync_patterns)
                attacked = self.attack(watermarked)
                pred_watermarks = self.decoder(attacked)
                
                # è®¡ç®—æŒ‡æ ‡
                pred_bits = (pred_watermarks > 0.5).float()
                ber = (pred_bits != watermarks).float().mean().item()
                psnr = compute_psnr(watermarked.cpu(), images.cpu())
                ssim = compute_ssim(watermarked.cpu(), images.cpu())
                
                test_metrics['ber'] += ber
                test_metrics['psnr'] += psnr
                test_metrics['ssim'] += ssim
        
        # å¹³å‡
        num_batches = len(self.test_loader)
        for k in test_metrics:
            test_metrics[k] /= num_batches
        
        # è®°å½•åˆ°TensorBoard
        for k, v in test_metrics.items():
            self.writer.add_scalar(f'test/{k}', v, epoch)
        
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        self.encoder.train()
        self.decoder.train()
        self.attack.train()
        
        return test_metrics


if __name__ == "__main__":
    # è®­ç»ƒé…ç½®
    data_dir = os.path.join(project_root, 'data/train_images')
    save_dir = os.path.join(project_root, 'results/checkpoints')
    log_dir = os.path.join(project_root, 'results/logs')
    
    # æ•°æ®éš”ç¦»è¯´æ˜
    print("\n" + "="*60)
    print("ğŸ“ æ•°æ®ç›®å½•è¯´æ˜:")
    print(f"  è®­ç»ƒé›†: {data_dir} (ç”¨äºè®­ç»ƒï¼Œä¼šè¢«æ¨¡å‹å­¦ä¹ )")
    print(f"  æµ‹è¯•é›†: {os.path.join(project_root, 'data/test_images')} (ç”¨äºéªŒè¯ï¼Œä¸ä¼šå‚ä¸è®­ç»ƒ)")
    print("  âœ… è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®å®Œå…¨éš”ç¦»ï¼Œä¸ä¼šç›¸äº’æ±¡æŸ“")
    print("  âœ… æµ‹è¯•é›†åªç”¨äºè¯„ä¼°ï¼Œä¸ä¼šè¿›è¡Œåå‘ä¼ æ’­")
    print("="*60 + "\n")
    config = {
        # æ•°æ®
        'train_dir': data_dir,  # éœ€è¦å‡†å¤‡å›¾åƒ
        'image_size': 256,
        'batch_size': 2,  # Mac M4å»ºè®®2-4ï¼ˆDDIMæ¨¡å‹è¾ƒå¤§ï¼Œéœ€è¦æ›´å¤šå†…å­˜ï¼‰
        'num_workers': 0,  # MPS ä¸‹é¿å…å¤šè¿›ç¨‹ pickle bch å¯¹è±¡ï¼›éœ€å¹¶å‘å¯æ”¹>0å¹¶é‡æ„é¢„å¤„ç†å®ä¾‹åŒ–æ–¹å¼
        
        # æ¨¡å‹
        'watermark_length': 640,  # 64bitåŸæ–‡ + BCH(127,64,10) + 512bitç­¾å
        
        # è®­ç»ƒ
        'epochs': 100,  # æ€»è®­ç»ƒè½®æ•°ï¼ˆå¯ä»¥è®¾ç½®å¤§ä¸€ç‚¹ï¼Œæ¯”å¦‚100è½®ï¼‰
        'lr': 0.0001,
        'lr_step': 20,
        'lambda_p': 1.0,
        'lambda_w': 10.0,
        
        # ä¿å­˜
        'save_dir': save_dir,
        'log_dir': log_dir,
        'save_interval': 10
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = WatermarkTrainer(config)
    
    # ========== è®­ç»ƒæ¨¡å¼é€‰æ‹© ==========
    
    # æ¨¡å¼1ï¼šåˆ†æ‰¹æ¬¡è®­ç»ƒï¼ˆæ¨èï¼‰- æ¯æ¬¡è®­ç»ƒ10è½®ï¼Œè‡ªåŠ¨ä¿å­˜å¹¶é€€å‡º
    # ä¸‹æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä»ä¸Šæ¬¡çš„checkpointç»§ç»­
    trainer.train(train_batch_epochs=10)
    
    # æ¨¡å¼2ï¼šå®Œæ•´è®­ç»ƒ - ä¸€æ¬¡æ€§è®­ç»ƒå®Œæ‰€æœ‰è½®æ•°
    # trainer.train()
    
    # æ¨¡å¼3ï¼šæ‰‹åŠ¨æŒ‡å®šæ¢å¤ç‚¹
    # trainer.train(resume_from='best')   # ä»æœ€ä½³æ¨¡å‹æ¢å¤
    # trainer.train(resume_from='latest') # ä»æœ€æ–°epochæ¢å¤
    # trainer.train(resume_from=None)     # å¼ºåˆ¶ä»å¤´å¼€å§‹
    # trainer.train(resume_from='path/to/checkpoint.pth')  # ä»æŒ‡å®šè·¯å¾„æ¢å¤